# proximal-policy-optimization
very simple implementation of the PPO algorithm for beginners
